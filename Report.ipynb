{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import make_scorer\nimport xgboost as xgb\n\ntrain = pd.read_csv(\"../input/statistical-learning-sapienza-spring-2022/train.csv\")\ntest = pd.read_csv(\"../input/statistical-learning-sapienza-spring-2022/test.csv\")\n\n# Preprocessing\n\ntest_id = test[\"id\"]\n\ntrain.drop(columns = [\"id\"], inplace = True)\ntest.drop(columns = [\"id\"], inplace = True)\n\nnew_train = train.drop(columns = [\"y\"])\ny_train = train[\"y\"]\n\n#print(train.shape)\n#print(test.shape)\n\n#print(train.describe())\n\n#print(new_train.isnull().values.any())\n#print(sorted(new_train.isnull().sum()))\n\nnew_train = new_train.fillna(value=np.mean(new_train)) # Filling missing values with column means (test NAs are filled with corresponding training set column means)\ntest = test.fillna(value=np.mean(new_train))\n\n#print(train[\"y\"].value_counts())\n\ncoeffs_var = []\n\nfor col in train.columns:\n    try: coeffs_var.append(train[col].std()/(train[col].mean()))\n    except Exception: continue\n\n#print(min(coeffs_var))\n\n#new_train.drop(columns = [\"month\", \"day\"], inplace = True)\n#test.drop(columns = [\"month\", \"day\"], inplace = True)\n\n# Centering columns\n# new_train = (new_train - np.mean(new_train)) / np.std(new_train)\n# test = (test - np.mean(new_train)) / np.std(new_train)\n\n# new_train = pd.get_dummies(new_train)\n# test = pd.get_dummies(test)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The main idea that guided our workflow was to extract relevant insights from the data of the 4 variables for which we had temporal values (SP, CS, FCD, AL). We ended up building few custom new features, by employing some standard statistical functionals, in order to obtain what we though could have been useful summaries of the whole data distribution. During the 48 hours we came up with several ideas, both in terms of possible new features and approaches (data preprocessing/models); most of them were implemented and the ones that didn't seem to provide any additional improvement to the model accuracy (in terms of the F1-Score) were discarded.\n\nThe features that ended up in our final model draft:\n\n* Mean of the 60 values of the SP, CS, FCD and AL variables\n* The Coefficient of variation (std / mean) of the 60 values of the above variables. From the data exploration, we saw that oftentimes these variables presented values extremely similar in consecutive steps (oftentimes equal); we therefore thought that the Coefficient of variation could provide a significant insight about the variability of the data *(variability is information!)*\n* The starting value of each of these variables\n* The difference between the first and the last values (at time t=1 and t=60) of the CS and AL variables","metadata":{}},{"cell_type":"code","source":"# Build training and set dataset (new features)\n\ntemp_train_1 = new_train.iloc[:,:3] # from_start, month, day columns\n\ntemp_train_1['sp_start'] = new_train[\"sp.1\"] # SP value at time t=1\n\ntemp_train_1['sp_mean'] = new_train.iloc[:,3:63].mean(axis=1) # SP mean (over 60 seconds)\n\ntemp_train_1['sp_coeff_var'] = new_train.iloc[:,3:63].std(axis=1)/new_train.iloc[:,4:63].mean(axis=1) # SP Coefficient of variation\n\ntemp_train_1['cs_start'] = new_train[\"cs.1\"] # CS value at time t=1\n\ntemp_train_1['cs_mean'] = new_train.iloc[:,63:123].mean(axis=1) # CS mean (over 60 seconds)\n\ntemp_train_1['cs_coeff_var'] = new_train.iloc[:,63:123].std(axis=1)/new_train.iloc[:,64:123].mean(axis=1) # CS Coefficient of variation\n\ntemp_train_1['cs_diff'] = new_train[\"cs.60\"]-new_train[\"cs.1\"] # CS (End value - Start value)\n\ntemp_train_1['fcd_start'] = new_train[\"fcd.1\"] # FCD value at time t=1\n\ntemp_train_1['fcd_mean'] = new_train.iloc[:,123:183].mean(axis=1) # FCD mean (over 60 seconds)\n\ntemp_train_1['fcd_coeff_var'] = new_train.iloc[:,123:183].std(axis=1)/new_train.iloc[:,124:183].mean(axis=1) # FCD Coefficient of variation\n\ntemp_train_1['al_start'] = new_train[\"al.1\"] # AL value at time t=1\n\ntemp_train_1['al_mean'] = new_train.iloc[:,183:].mean(axis=1) # AL mean (over 60 seconds)\n\ntemp_train_1['al_coeff_var'] = new_train.iloc[:,183:].std(axis=1)/new_train.iloc[:,184:].mean(axis=1) # AL Coefficient of variation\n\ntemp_train_1['al_diff'] = new_train[\"al.60\"]-new_train[\"al.1\"] # CS (End value - Start value)\n\nnew_train_2 = temp_train_1\n\ntemp_test_1 = test.iloc[:,:3]\ntemp_test_1['sp_start'] = test[\"sp.1\"]\ntemp_test_1['sp_mean'] = test.iloc[:,3:63].mean(axis=1)\ntemp_test_1['sp_coeff_var'] = test.iloc[:,3:63].std(axis=1)/test.iloc[:,4:63].mean(axis=1)\ntemp_test_1['cs_start'] = test[\"cs.1\"]\ntemp_test_1['cs_mean'] = test.iloc[:,63:123].mean(axis=1)\ntemp_test_1['cs_coeff_var'] = test.iloc[:,63:123].std(axis=1)/test.iloc[:,64:123].mean(axis=1)\ntemp_test_1['cs_diff'] = test[\"cs.60\"]-test[\"cs.1\"]\ntemp_test_1['fcd_start'] = test[\"fcd.1\"]\ntemp_test_1['fcd_mean'] = test.iloc[:,123:183].mean(axis=1)\ntemp_test_1['fcd_coeff_var'] = test.iloc[:,123:183].std(axis=1)/test.iloc[:,124:183].mean(axis=1)\ntemp_test_1['al_start'] = test[\"al.1\"]\ntemp_test_1['al_mean'] = test.iloc[:,183:].mean(axis=1)\ntemp_test_1['al_coeff_var'] = test.iloc[:,183:].std(axis=1)/test.iloc[:,184:].mean(axis=1)\ntemp_test_1['al_diff'] = test[\"al.60\"]-test[\"al.1\"]\nnew_test_2 = temp_test_1","metadata":{"execution":{"iopub.status.busy":"2022-06-30T22:19:20.700136Z","iopub.execute_input":"2022-06-30T22:19:20.700647Z","iopub.status.idle":"2022-06-30T22:19:20.845958Z","shell.execute_reply.started":"2022-06-30T22:19:20.700608Z","shell.execute_reply":"2022-06-30T22:19:20.845102Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"new_train = new_train_2\ntest = new_test_2","metadata":{"execution":{"iopub.status.busy":"2022-06-30T22:19:20.847522Z","iopub.execute_input":"2022-06-30T22:19:20.848247Z","iopub.status.idle":"2022-06-30T22:19:20.854445Z","shell.execute_reply.started":"2022-06-30T22:19:20.848203Z","shell.execute_reply":"2022-06-30T22:19:20.853373Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# One-Hot encoding of categorical variables (Month and Day)\n\nnew_train = pd.get_dummies(new_train)\ntest = pd.get_dummies(test)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T22:19:20.858101Z","iopub.execute_input":"2022-06-30T22:19:20.858502Z","iopub.status.idle":"2022-06-30T22:19:20.883220Z","shell.execute_reply.started":"2022-06-30T22:19:20.858464Z","shell.execute_reply":"2022-06-30T22:19:20.882345Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Due to the nature of the problem (Multi-Class Classification where the different classes presented an intrinsic order), we decided to approach it as a Regression problem.\n\nWe built custom functions in order to cast the class labels to numbers and viceversa at the scoring and at the predicting stage. The casting function was realized in such a way that the resulting numbers where equidistant (since we wanted them to resemble the class structures); also the Zone-0, for which we had no precise HR information coming from the dataset description, was subject to the same rules. The actual value distribution was chosen via a grid-search approach: we in fact noticed that picking numbers of different magnitudes did impact the final model accuracy (we are aware that this is something rather odd and rarely happens with most well-known models, but the combination of our modelling of the problem and the model chosen - XGBoost - actually required further tuning).\n\nThe values that made it to the final draft in the end where the ones corresponding to the mean of the percentage values at the boundaries of the original intervals (multiplied by 100).\n\nWe came up with our custom scorer, that performed the conversion from numbers back to classes and computed the F1_weighted score. We went for the \"weighted\" version, which alters the default \"macro\" measure in order to account for label imbalance (we did in fact observe that only few observations were labelled with the \"Zone-0\" and \"Zone-1\" classes)","metadata":{}},{"cell_type":"code","source":"def myclass(x):\n    if(x<=50): return \"Zone-0\"\n    elif(x<=60): return \"Zone-1\"\n    elif(x<=70): return \"Zone-2\"\n    elif(x<=80): return \"Zone-3\"\n    elif(x<=90): return \"Zone-4\"\n    else: return \"Zone-5\"\n\ndef mynumber(x):\n    if(x==\"Zone-0\"): return 45\n    elif(x==\"Zone-1\"): return 55\n    elif(x==\"Zone-2\"): return 65\n    elif(x==\"Zone-3\"): return 75\n    elif(x==\"Zone-4\"): return 85\n    else: return 95\n\ndef myf1scorer(pred,actual,avg=\"weighted\"):\n    class_pred = [myclass(x) for x in pred]\n    actual_pred = [myclass(x) for x in actual]\n    return f1_score(actual_pred,class_pred,average=avg)\n\nmyscorer = make_scorer(myf1scorer, greater_is_better=True)\n\ny_train = [mynumber(x) for x in y_train]\n\nprint(new_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T22:19:20.886032Z","iopub.execute_input":"2022-06-30T22:19:20.886417Z","iopub.status.idle":"2022-06-30T22:19:20.902340Z","shell.execute_reply.started":"2022-06-30T22:19:20.886379Z","shell.execute_reply":"2022-06-30T22:19:20.901577Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"(12997, 31)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The final dataset presented 31 features (far less than the original 243)","metadata":{}},{"cell_type":"markdown","source":"The model selected for the final draft was eXtremeGradientBoosting regressor.\n\nThe first approach to the problem was via another (well-known) tree-based model: Random Forest. We initially followed this path since we are aware that those models are extremely flexible in terms of range of problems they are able to address with a very shallow tuning, and are therefore often our ice-breaking choice. Having observed fairly good results in terms of accuracy in the early attempts, we decided to stick with tree-based models, and focused our attention on XGB, since we believed that applying the *boosting* technique to our few, custom built features could provide satisfactory outcomes.\n\nThe tuning phase was carried out following both a grid-search and a manual, local parameter optimization approach. While the model did not require too much time to train at each iteration, it did however need for a fine-grained tuning in order to perform well. XGB presents a fairly large number of hyperparameters that can be tuned; we only addressed the ones we thought could affect accuracy under our settings.\n\nOur final choices are listed below:\n\n* Booster: dart (Tree-based)\n* Eta (Learning rate): 0.092 \n* Max Depth (of a tree): 9\n* Lambda (L2 regularization term): 0.22\n* Alpha (L1 regularization term): 1.5*(1e-5)\n* Gamma (min_split_loss): 1e-4\n* Min_child_weight (minimum number of instances needed to be in each node): 0 (Extremely not-conservative)\n\nThe model was trained via 5-fold CV; the fold error was computed using the custom scorer","metadata":{}},{"cell_type":"code","source":"random.seed(42)\n\nxgb = xgb.XGBRegressor()\npipeline = Pipeline(steps=[(\"XGB\", xgb)])\nparam_grid = {\"XGB__booster\": [\"dart\"], \"XGB__eta\": [0.092], \"XGB__max_depth\": [9], \"XGB__lambda\":[0.22],\"XGB__alpha\":[1.5*(1e-5)], \"XGB__gamma\": [1e-4], \"XGB__min_child_weight\":[0]}\nsearch = GridSearchCV(pipeline, param_grid,n_jobs=-1,cv=5, scoring=myscorer, verbose=3)\nsearch.fit(new_train, y_train)\nprint(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\nprint(search.best_score_)\nprint(search.best_params_)\npred = search.predict(test)\npred = [myclass(x) for x in pred]\nout_df = pd.DataFrame.from_dict({\"id\": test_id, \"target\": pred})\nout_df.to_csv(r\"./XGB.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T22:19:20.903663Z","iopub.execute_input":"2022-06-30T22:19:20.904471Z","iopub.status.idle":"2022-06-30T22:20:02.242920Z","shell.execute_reply.started":"2022-06-30T22:19:20.904437Z","shell.execute_reply":"2022-06-30T22:20:02.241793Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 1 candidates, totalling 5 fits\nBest parameter (CV score=0.738):\n0.7378132493505627\n{'XGB__alpha': 1.5000000000000002e-05, 'XGB__booster': 'dart', 'XGB__eta': 0.092, 'XGB__gamma': 0.0001, 'XGB__lambda': 0.22, 'XGB__max_depth': 9, 'XGB__min_child_weight': 0}\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n\nsns.heatmap(confusion_matrix([myclass(x) for x in y_train],[myclass(x) for x in search.predict(new_train)]), annot=True, cmap=\"YlGnBu\", fmt='g')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T22:20:02.244675Z","iopub.execute_input":"2022-06-30T22:20:02.245001Z","iopub.status.idle":"2022-06-30T22:20:03.025711Z","shell.execute_reply.started":"2022-06-30T22:20:02.244973Z","shell.execute_reply":"2022-06-30T22:20:03.024587Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"The final model exhibited a 0.738 CV F1-score on the training set. When the predicted output was submitted to the Kaggle competition, the score on the \"public\" portion of the test set was even higher (relieving us of our main concern: overfitting while training).\n\nThe confusion matrix shows the performance of the model on the training set. XGB behaved extremely well in predicting the least frequent classes \"Zone-0\" and \"Zone-1\", while most of the incorrect predictions find their true value in the most frequent classes \"Zone-3\" and \"Zone-4\" (which is rather reasonable). In addition, basically all the incorrect values are actually classified in a Zone adjacent to the true one, which is a significant point of strength for our model.\n\nThe model was able to achieve a fairly good accuracy with only a small set of custom built features; we are confident it could be possible to increase it even further with a small effort by applying domain-specific knowledge () in order to realize even more informative features (we did try during the second day of work, but failed miserabily due to lack of the aforementioned knowledge :) )","metadata":{}},{"cell_type":"markdown","source":"**What we tried during the 48hrs and didn't end up in our final draft (A.K.A the long TBD silence..)**\n\n- Feature Scaling/Normalizing (usually not required by tree-based models)\n- Handling categorical non-target features differently:\n       - Months: dropping them, encoding with custom functions (3 groups based on climate/seasons - both as categories and as numbers; replacing them with sin and cos values in order to account for cyclicality)","metadata":{}},{"cell_type":"code","source":"def heat(x):\n    if(x==\"Dec\" or x==\"Jan\" or x==\"Feb\"): return \"Cold\"\n    elif(x==\"Jun\" or x==\"Jul\" or x==\"Aug\"): return \"Hot\"\n    else: return \"Warm\"\n\ndef month_num(x):\n    months = {\"Jan\":1,\"Feb\":2,\"Mar\":3,\"Apr\":4,\"May\":5,\"Jun\":6,\"Jul\":7,\"Aug\":8,\"Sep\":9,\"Oct\":10,\"Nov\":11,\"Dec\":12}\n    months_num = []\n    for el in x:\n        months_num.append(months[el])\n    return np.array(months_num)\n\ntemp_train_1['month_sin'] = np.sin((month_num(new_train[\"month\"])-1)(2.np.pi/12))\ntemp_train_1['month_cos'] = np.cos((month_num(new_train[\"month\"])-1)(2.np.pi/12))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Dimensionality Reduction: kPCA\n* Different models:\n    - Regression: SVR, Random Forest\n    - Classification: Random Forest Classifier, OneVsRestClassifier + XGBClassifier()\n* Adding different custom features: higher order moments (3,4), quantiles, combinations of SP, CD, FDC and AL in order to come up with some metric tracking \"effort level\" (e.g. Appoximating Steps Per Minute with the equation: (CD + FDC)*2) \n* Time-window approach: aggregating the 60 measurements via a sliding window approach (of different sizes - overlapping and not), in a \"time-series analysis fashion\"","metadata":{}},{"cell_type":"code","source":"def third_mom(x):\n    col = []\n    for i in range(x.shape[0]):\n        col.append(moment(x.iloc[i,:],moment=3))\n    return col\n\n#####\n\nvalues_tr = []\nvalues_te = []\n\nfor t in range(new_train.shape[0]):\n    values_train = []\n    values_test = []\n    windowsize = 10\n    for i in range(int(60/windowsize)):\n        k=183+windowsize*i\n        for f in range(windowsize):\n            values_train.append(new_train.iloc[t,k+winsize-1]/new_train.iloc[t,k])\n            values_test.append(test.iloc[t,k+winsize-1]/test.iloc[t,k])\n    values_tr.append(np.array(values_train)*new_train.iloc[t,3:63]*(new_train.iloc[t,63:123]+new_train.iloc[t,123:183])*2)\n    values_te.append(np.array(values_test)*test.iloc[t,3:63]*(test.iloc[t,63:123]+test.iloc[t,123:183])*2)\n\n#####\n    \nfor t in range(new_train.shape[0]):\n    values_train = []\n    for i in range(int(60/windowsize)):\n        k=183+windowsize*i\n        for f in range(windowsize):\n            values_train.append(new_train.iloc[t,k+windowsize-1]-new_train.iloc[t,k])\n    #values_tr.append(np.array(values_train)*np.array(new_train.iloc[t,3:63])*(np.array(new_train.iloc[t,63:123])+np.array(new_train.iloc[t,123:183]))*2)\n    delta_al = np.array(values_train)\n    spm = (np.array(new_train.iloc[t,63:123])+np.array(new_train.iloc[t,123:183]))*2\n    row = []\n    for i in range(len(delta_al)):\n        if delta_al[i]>=0: row.append(delta_al[i]/spm[i])\n        else: row.append(delta_al[i]*spm[i])\n    values_tr.append(np.array(row))\n    \n#####\n\nfor t in range(test.shape[0]):\n    values_test = []\n    for i in range(int(60/windowsize)):\n        k=63+windowsize*i\n        for f in range(windowsize):\n            values_test.append(2*(test.iloc[t,k+windowsize-1]+test.iloc[t,k+60+windowsize-1])-2*(test.iloc[t,k]+test.iloc[t,k+60]))\n    values_te.append(np.array(values_test))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T22:20:03.042754Z","iopub.status.idle":"2022-06-30T22:20:03.043605Z","shell.execute_reply.started":"2022-06-30T22:20:03.043347Z","shell.execute_reply":"2022-06-30T22:20:03.043372Z"},"trusted":true},"execution_count":null,"outputs":[]}]}